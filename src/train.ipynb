{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4808c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detector_model.model import ObjectDetectionModel\n",
    "from models.detector_model.processor import TrainingProcessor\n",
    "from models.detector_model.data_utils import TrainingDataset, COCOProcessor\n",
    "from models.detector_model.loss_grid import ObjectDetectionLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "grouped_classes = {\n",
    "        \"Metal\": [\n",
    "            \"Metal bottle cap\", \"Metal lid\", \"Drink can\", \"Pop tab\", \"Scrap metal\",\n",
    "            \"Food Can\", \"Aluminium blister pack\", \"Aluminium foil\", \"Aerosol\"\n",
    "        ],\n",
    "        \"Plastic\": [\n",
    "            \"Plastic bottle cap\", \"Other plastic wrapper\", \"Six pack rings\",\n",
    "            \"Single-use carrier bag\", \"Plastic straw\", \"Plastic glooves\",\n",
    "            \"Plastic utensils\", \"Disposable plastic cup\", \"Other plastic bottle\",\n",
    "            \"Tupperware\", \"Spread tub\", \"Garbage bag\", \"Other plastic container\",\n",
    "            \"Other plastic\", \"Rope & strings\", \"Other plastic cup\", \"Plastic film\",\n",
    "            \"Polypropylene bag\", \"Plastic lid\", \"Clear plastic bottle\", \"Squeezable tube\",\n",
    "            \"Carded blister pack\", \"Crisp packet\", \"Meal carton\"\n",
    "        ],\n",
    "        \"Paper\": [\n",
    "            \"Paper cup\", \"Paper bag\", \"Normal paper\", \"Paper straw\", \"Tissues\",\n",
    "            \"Toilet tube\", \"Wrapping paper\", \"Pizza box\", \"Magazine paper\",\n",
    "            \"Corrugated carton\", \"Egg carton\", \"Other carton\", \"Drink carton\"\n",
    "        ],\n",
    "        \"Glass\": [\n",
    "            \"Glass jar\", \"Glass bottle\", \"Glass cup\", \"Broken glass\"\n",
    "        ],\n",
    "        \"Waste\": [\n",
    "            \"Cigarette\", \"Food waste\", \"Foam cup\",\n",
    "            \"Disposable food container\", \"Foam food container\",\n",
    "            \"Shoe\", \"Unlabeled litter\", \"Styrofoam piece\"\n",
    "        ],\n",
    "        \"Battery\": [\n",
    "            \"Battery\"\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0db955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "==================================================\n",
      "Total parameters:      416,801\n",
      "Trainable parameters:  416,801\n",
      "Non-trainable params:  0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model = ObjectDetectionModel(num_classes=len(grouped_classes), num_anchors=3, grid_size=3)\n",
    "# model.load_state_dict(torch.load('D:\\Sakal\\AI_FARM\\Recycling_Classification\\src\\checkpoint_latest.pth')['model_state_dict'])\n",
    "model.count_parameters()\n",
    "coco_processor = COCOProcessor(classes=grouped_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d701f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_trash = coco_processor.extract_annotations(\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/Dataset/Trash Detection.v14i.coco/train/_annotations.coco.json',\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/Dataset/Trash Detection.v14i.coco/train',\n",
    "    convert=False\n",
    ")\n",
    "\n",
    "extracted_taco = coco_processor.extract_annotations(\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/TACO/data/annotations.json',\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/TACO/data',\n",
    "    convert=True\n",
    ")\n",
    "\n",
    "classes_names_trash = []\n",
    "for label in extracted_trash:\n",
    "    classes_names_trash.extend(label['Class'])\n",
    "classes_names_trash = list(set(classes_names_trash))\n",
    "\n",
    "classes_names_taco = []\n",
    "for label in extracted_taco:\n",
    "    classes_names_taco.extend(label['Class'])\n",
    "classes_names_taco = list(set(classes_names_taco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b27d084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = extracted_taco + extracted_trash\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef08bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "classes = [item for item, value in grouped_classes.items()] # ['Metal', 'Plastic', 'Paper', 'Glass', 'Waste', 'Battery']\n",
    "\n",
    "processor = TrainingProcessor(\n",
    "    input_size=448,\n",
    "    grid_size=model.grid_size,\n",
    "    num_anchors=model.num_anchors,\n",
    "    classes=classes,\n",
    ")\n",
    "\n",
    "trash_dataset = TrainingDataset(data_json=dataset, processor=processor, is_training=False)\n",
    "trash_dataloader = DataLoader(trash_dataset, batch_size=40, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ceb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = ObjectDetectionLoss(processor=processor, bbox_loss_weight=1.0, cls_loss_weight=2.0, obj_loss_weight=2.0, pos_obj_weight=1.5, neg_obj_weight=0.5)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,           # learning rate\n",
    "    betas=(0.9, 0.999),# beta1 and beta2 for momentum estimates\n",
    "    eps=1e-8,          # small constant for numerical stability\n",
    "    weight_decay=0     # L2 regularization\n",
    ")\n",
    "\n",
    "num_epochs = 50\n",
    "batch_interval = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487635a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_tensor, target_tensor, anchor_pose = processor.process_training_sample(\n",
    "#     extracted_trash[1530], apply_augmentation=False, get_anchors=True)\n",
    "\n",
    "# model.to(device)\n",
    "# with torch.no_grad():\n",
    "#     output = model(image_tensor.unsqueeze(0).to(device))\n",
    "\n",
    "# bboxes = processor.convert_output_to_bboxes(output[0], grid=True, class_tensor=True, conf_threshold=None)\n",
    "\n",
    "# neg_processed_bboxes = []\n",
    "# for item in bboxes:\n",
    "#     bbox = {\n",
    "#         'bbox': item['bbox'],\n",
    "#         'conf': torch.sigmoid(item['conf']),\n",
    "#         'class_tensor': torch.sigmoid(item['class_tensor']),\n",
    "#         'grid': item['grid'],\n",
    "#         'class_id': torch.argmax(torch.sigmoid(item['class_tensor']))\n",
    "#     }\n",
    "#     if torch.sigmoid(item['conf']) > 0.32:\n",
    "#         neg_processed_bboxes.append(bbox)\n",
    "\n",
    "# neg_processed_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268a8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.draw_bbox_on_image(image_tensor, neg_processed_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33cb5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor = train_with_monitoring(\n",
    "#     model=model,\n",
    "#     dataloader=trash_dataloader,\n",
    "#     loss_fn=criterion,\n",
    "#     optimizer=optimizer,\n",
    "#     num_epochs=50,\n",
    "#     save_model_path='best_model.pth',\n",
    "#     monitor_frequency=200, \n",
    "#     device='cuda'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc997375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: [25/188], Interval Loss: 0.5726, Epoch Loss: 0.5726, Lifetime Loss: 0.5726\n",
      "\t\tciou Loss: 0.2456081360578537, Objectness Loss: 0.20305056869983673, Positive Objectness Loss: 0.6890256404876709, Class Loss: 0.12390400469303131,\n",
      "\tBatch: [50/188], Interval Loss: 0.5544, Epoch Loss: 0.5745, Lifetime Loss: 0.5745\n",
      "\t\tciou Loss: 0.2485014945268631, Objectness Loss: 0.20168587565422058, Positive Objectness Loss: 0.678826093673706, Class Loss: 0.12436062097549438,\n",
      "\tBatch: [75/188], Interval Loss: 0.4851, Epoch Loss: 0.5515, Lifetime Loss: 0.5515\n",
      "\t\tciou Loss: 0.23841601610183716, Objectness Loss: 0.19394990801811218, Positive Objectness Loss: 0.6671144366264343, Class Loss: 0.11914939433336258,\n",
      "\tBatch: [100/188], Interval Loss: 0.4454, Epoch Loss: 0.5297, Lifetime Loss: 0.5297\n",
      "\t\tciou Loss: 0.2288467139005661, Objectness Loss: 0.18687878549098969, Positive Objectness Loss: 0.6595014929771423, Class Loss: 0.11393117159605026,\n",
      "\tBatch: [125/188], Interval Loss: 0.4250, Epoch Loss: 0.5123, Lifetime Loss: 0.5123\n",
      "\t\tciou Loss: 0.22135648131370544, Objectness Loss: 0.18145084381103516, Positive Objectness Loss: 0.6537027955055237, Class Loss: 0.10945065319538116,\n",
      "\tBatch: [150/188], Interval Loss: 0.4471, Epoch Loss: 0.5044, Lifetime Loss: 0.5044\n",
      "\t\tciou Loss: 0.21844777464866638, Objectness Loss: 0.17923125624656677, Positive Objectness Loss: 0.649671733379364, Class Loss: 0.10674768686294556,\n",
      "\tBatch: [175/188], Interval Loss: 0.4214, Epoch Loss: 0.4950, Lifetime Loss: 0.4950\n",
      "\t\tciou Loss: 0.21478784084320068, Objectness Loss: 0.1762653887271881, Positive Objectness Loss: 0.6424615383148193, Class Loss: 0.10396797209978104,\n",
      "Epoch: [1/50], Avg Epoch Loss: 0.4918, Avg Lifetime Loss: 0.4918\n",
      "\tBatch: [25/188], Interval Loss: 0.4121, Epoch Loss: 0.4121, Lifetime Loss: 0.4821\n",
      "\t\tciou Loss: 0.1804533302783966, Objectness Loss: 0.1506458818912506, Positive Objectness Loss: 0.6001112461090088, Class Loss: 0.08100903034210205,\n",
      "\tBatch: [50/188], Interval Loss: 0.3993, Epoch Loss: 0.4136, Lifetime Loss: 0.4751\n",
      "\t\tciou Loss: 0.18185226619243622, Objectness Loss: 0.15124492347240448, Positive Objectness Loss: 0.6028385162353516, Class Loss: 0.08053889870643616,\n",
      "\tBatch: [75/188], Interval Loss: 0.4018, Epoch Loss: 0.4150, Lifetime Loss: 0.4697\n",
      "\t\tciou Loss: 0.18276070058345795, Objectness Loss: 0.1523083597421646, Positive Objectness Loss: 0.6002087593078613, Class Loss: 0.07995514571666718,\n",
      "\tBatch: [100/188], Interval Loss: 0.3887, Epoch Loss: 0.4124, Lifetime Loss: 0.4640\n",
      "\t\tciou Loss: 0.18135488033294678, Objectness Loss: 0.15191984176635742, Positive Objectness Loss: 0.5981309413909912, Class Loss: 0.07908792048692703,\n",
      "\tBatch: [125/188], Interval Loss: 0.4082, Epoch Loss: 0.4148, Lifetime Loss: 0.4609\n",
      "\t\tciou Loss: 0.18280023336410522, Objectness Loss: 0.15315116941928864, Positive Objectness Loss: 0.5968230962753296, Class Loss: 0.07883445918560028,\n",
      "\tBatch: [150/188], Interval Loss: 0.4042, Epoch Loss: 0.4157, Lifetime Loss: 0.4579\n",
      "\t\tciou Loss: 0.1836651712656021, Objectness Loss: 0.15371236205101013, Positive Objectness Loss: 0.5972162485122681, Class Loss: 0.07833791524171829,\n",
      "\tBatch: [175/188], Interval Loss: 0.4079, Epoch Loss: 0.4169, Lifetime Loss: 0.4556\n",
      "\t\tciou Loss: 0.18456076085567474, Objectness Loss: 0.1542685627937317, Positive Objectness Loss: 0.5941258668899536, Class Loss: 0.07808858901262283,\n",
      "Epoch: [2/50], Avg Epoch Loss: 0.4164, Avg Lifetime Loss: 0.4541\n",
      "\tBatch: [25/188], Interval Loss: 0.3997, Epoch Loss: 0.3997, Lifetime Loss: 0.4506\n",
      "\t\tciou Loss: 0.17720283567905426, Objectness Loss: 0.15119747817516327, Positive Objectness Loss: 0.5721470713615417, Class Loss: 0.07134149968624115,\n",
      "\tBatch: [50/188], Interval Loss: 0.3771, Epoch Loss: 0.3960, Lifetime Loss: 0.4472\n",
      "\t\tciou Loss: 0.17587265372276306, Objectness Loss: 0.14946874976158142, Positive Objectness Loss: 0.5732811689376831, Class Loss: 0.07069385796785355,\n",
      "\tBatch: [75/188], Interval Loss: 0.4101, Epoch Loss: 0.4061, Lifetime Loss: 0.4460\n",
      "\t\tciou Loss: 0.18082161247730255, Objectness Loss: 0.15348772704601288, Positive Objectness Loss: 0.5769734978675842, Class Loss: 0.07174128293991089,\n",
      "\tBatch: [100/188], Interval Loss: 0.3791, Epoch Loss: 0.4031, Lifetime Loss: 0.4433\n",
      "\t\tciou Loss: 0.1794278770685196, Objectness Loss: 0.15264222025871277, Positive Objectness Loss: 0.5766535401344299, Class Loss: 0.07106208801269531,\n",
      "\tBatch: [125/188], Interval Loss: 0.3760, Epoch Loss: 0.4007, Lifetime Loss: 0.4407\n",
      "\t\tciou Loss: 0.17823390662670135, Objectness Loss: 0.1518627107143402, Positive Objectness Loss: 0.5788336396217346, Class Loss: 0.07064632326364517,\n",
      "\tBatch: [150/188], Interval Loss: 0.3747, Epoch Loss: 0.3989, Lifetime Loss: 0.4383\n",
      "\t\tciou Loss: 0.17768536508083344, Objectness Loss: 0.15122482180595398, Positive Objectness Loss: 0.5771251320838928, Class Loss: 0.06999973952770233,\n",
      "\tBatch: [175/188], Interval Loss: 0.3703, Epoch Loss: 0.3970, Lifetime Loss: 0.4359\n",
      "\t\tciou Loss: 0.17700834572315216, Objectness Loss: 0.15054570138454437, Positive Objectness Loss: 0.5778590440750122, Class Loss: 0.06939667463302612,\n",
      "Epoch: [3/50], Avg Epoch Loss: 0.3964, Avg Lifetime Loss: 0.4349\n",
      "\tBatch: [25/188], Interval Loss: 0.3798, Epoch Loss: 0.3798, Lifetime Loss: 0.4324\n",
      "\t\tciou Loss: 0.16914618015289307, Objectness Loss: 0.14575283229351044, Positive Objectness Loss: 0.5660992860794067, Class Loss: 0.06492681801319122,\n",
      "\tBatch: [50/188], Interval Loss: 0.3630, Epoch Loss: 0.3787, Lifetime Loss: 0.4302\n",
      "\t\tciou Loss: 0.16818806529045105, Objectness Loss: 0.14597566425800323, Positive Objectness Loss: 0.5710015296936035, Class Loss: 0.06453420221805573,\n",
      "\tBatch: [75/188], Interval Loss: 0.3751, Epoch Loss: 0.3825, Lifetime Loss: 0.4286\n",
      "\t\tciou Loss: 0.17030219733715057, Objectness Loss: 0.14722535014152527, Positive Objectness Loss: 0.5736380219459534, Class Loss: 0.06493724137544632,\n",
      "\tBatch: [100/188], Interval Loss: 0.3740, Epoch Loss: 0.3841, Lifetime Loss: 0.4272\n",
      "\t\tciou Loss: 0.171578049659729, Objectness Loss: 0.14747565984725952, Positive Objectness Loss: 0.5734668374061584, Class Loss: 0.06500888615846634,\n",
      "\tBatch: [125/188], Interval Loss: 0.3666, Epoch Loss: 0.3835, Lifetime Loss: 0.4255\n",
      "\t\tciou Loss: 0.1714918315410614, Objectness Loss: 0.1473027616739273, Positive Objectness Loss: 0.5730273127555847, Class Loss: 0.06470871716737747,\n",
      "\tBatch: [150/188], Interval Loss: 0.3755, Epoch Loss: 0.3847, Lifetime Loss: 0.4243\n",
      "\t\tciou Loss: 0.17197515070438385, Objectness Loss: 0.14806616306304932, Positive Objectness Loss: 0.5734426379203796, Class Loss: 0.06462650746107101,\n",
      "\tBatch: [175/188], Interval Loss: 0.3751, Epoch Loss: 0.3854, Lifetime Loss: 0.4231\n",
      "\t\tciou Loss: 0.17240409553050995, Objectness Loss: 0.1487133800983429, Positive Objectness Loss: 0.5738285183906555, Class Loss: 0.06431780010461807,\n",
      "Epoch: [4/50], Avg Epoch Loss: 0.3860, Avg Lifetime Loss: 0.4226\n",
      "\tBatch: [25/188], Interval Loss: 0.3818, Epoch Loss: 0.3818, Lifetime Loss: 0.4213\n",
      "\t\tciou Loss: 0.1720779538154602, Objectness Loss: 0.14768707752227783, Positive Objectness Loss: 0.5621113181114197, Class Loss: 0.06201730668544769,\n",
      "\tBatch: [50/188], Interval Loss: 0.3785, Epoch Loss: 0.3876, Lifetime Loss: 0.4204\n",
      "\t\tciou Loss: 0.17446674406528473, Objectness Loss: 0.15092657506465912, Positive Objectness Loss: 0.563575029373169, Class Loss: 0.062190063297748566,\n",
      "\tBatch: [75/188], Interval Loss: 0.3689, Epoch Loss: 0.3863, Lifetime Loss: 0.4193\n",
      "\t\tciou Loss: 0.1738549917936325, Objectness Loss: 0.15131913125514984, Positive Objectness Loss: 0.5665977597236633, Class Loss: 0.06110557168722153,\n",
      "\tBatch: [100/188], Interval Loss: 0.3629, Epoch Loss: 0.3841, Lifetime Loss: 0.4181\n",
      "\t\tciou Loss: 0.17288751900196075, Objectness Loss: 0.15012870728969574, Positive Objectness Loss: 0.5685715079307556, Class Loss: 0.06108193099498749,\n",
      "\tBatch: [125/188], Interval Loss: 0.3708, Epoch Loss: 0.3844, Lifetime Loss: 0.4172\n",
      "\t\tciou Loss: 0.17300865054130554, Objectness Loss: 0.15034496784210205, Positive Objectness Loss: 0.5698697566986084, Class Loss: 0.061050888150930405,\n",
      "\tBatch: [150/188], Interval Loss: 0.3405, Epoch Loss: 0.3794, Lifetime Loss: 0.4154\n",
      "\t\tciou Loss: 0.17049318552017212, Objectness Loss: 0.14855791628360748, Positive Objectness Loss: 0.567000687122345, Class Loss: 0.06034664064645767,\n",
      "\tBatch: [175/188], Interval Loss: 0.3605, Epoch Loss: 0.3788, Lifetime Loss: 0.4143\n",
      "\t\tciou Loss: 0.1703364998102188, Objectness Loss: 0.14846447110176086, Positive Objectness Loss: 0.568371057510376, Class Loss: 0.05995969474315643,\n",
      "Epoch: [5/50], Avg Epoch Loss: 0.3788, Avg Lifetime Loss: 0.4139\n",
      "\tBatch: [25/188], Interval Loss: 0.3659, Epoch Loss: 0.3659, Lifetime Loss: 0.4126\n",
      "\t\tciou Loss: 0.16560710966587067, Objectness Loss: 0.1444052904844284, Positive Objectness Loss: 0.5615121722221375, Class Loss: 0.05587193742394447,\n",
      "\tBatch: [50/188], Interval Loss: 0.3536, Epoch Loss: 0.3668, Lifetime Loss: 0.4115\n",
      "\t\tciou Loss: 0.1665414422750473, Objectness Loss: 0.14452698826789856, Positive Objectness Loss: 0.560201108455658, Class Loss: 0.055716414004564285,\n",
      "\tBatch: [75/188], Interval Loss: 0.3650, Epoch Loss: 0.3710, Lifetime Loss: 0.4107\n",
      "\t\tciou Loss: 0.1686326563358307, Objectness Loss: 0.14633139967918396, Positive Objectness Loss: 0.5620564818382263, Class Loss: 0.056048307567834854,\n",
      "\tBatch: [100/188], Interval Loss: 0.3503, Epoch Loss: 0.3694, Lifetime Loss: 0.4096\n",
      "\t\tciou Loss: 0.1673225313425064, Objectness Loss: 0.1460077315568924, Positive Objectness Loss: 0.5660380721092224, Class Loss: 0.056022271513938904,\n",
      "\tBatch: [125/188], Interval Loss: 0.3581, Epoch Loss: 0.3700, Lifetime Loss: 0.4087\n",
      "\t\tciou Loss: 0.16741414368152618, Objectness Loss: 0.14627617597579956, Positive Objectness Loss: 0.56618732213974, Class Loss: 0.05627813562750816,\n",
      "\tBatch: [150/188], Interval Loss: 0.3586, Epoch Loss: 0.3705, Lifetime Loss: 0.4079\n",
      "\t\tciou Loss: 0.16751308739185333, Objectness Loss: 0.14675793051719666, Positive Objectness Loss: 0.5656379461288452, Class Loss: 0.056194912642240524,\n",
      "\tBatch: [175/188], Interval Loss: 0.3701, Epoch Loss: 0.3725, Lifetime Loss: 0.4074\n",
      "\t\tciou Loss: 0.16861537098884583, Objectness Loss: 0.14774669706821442, Positive Objectness Loss: 0.567340075969696, Class Loss: 0.05614924058318138,\n",
      "Epoch: [6/50], Avg Epoch Loss: 0.3724, Avg Lifetime Loss: 0.4070\n",
      "\tBatch: [25/188], Interval Loss: 0.3687, Epoch Loss: 0.3687, Lifetime Loss: 0.4061\n",
      "\t\tciou Loss: 0.16742323338985443, Objectness Loss: 0.14818920195102692, Positive Objectness Loss: 0.5696914196014404, Class Loss: 0.05311935767531395,\n",
      "\tBatch: [50/188], Interval Loss: 0.3660, Epoch Loss: 0.3746, Lifetime Loss: 0.4056\n",
      "\t\tciou Loss: 0.17103111743927002, Objectness Loss: 0.14942173659801483, Positive Objectness Loss: 0.5685434937477112, Class Loss: 0.0541377030313015,\n",
      "\tBatch: [75/188], Interval Loss: 0.3351, Epoch Loss: 0.3660, Lifetime Loss: 0.4044\n",
      "\t\tciou Loss: 0.16700543463230133, Objectness Loss: 0.14617657661437988, Positive Objectness Loss: 0.5616002678871155, Class Loss: 0.05281686782836914,\n",
      "\tBatch: [100/188], Interval Loss: 0.3481, Epoch Loss: 0.3650, Lifetime Loss: 0.4035\n",
      "\t\tciou Loss: 0.16699090600013733, Objectness Loss: 0.14572089910507202, Positive Objectness Loss: 0.5613856315612793, Class Loss: 0.052310287952423096,\n",
      "\tBatch: [125/188], Interval Loss: 0.3563, Epoch Loss: 0.3661, Lifetime Loss: 0.4029\n",
      "\t\tciou Loss: 0.16754356026649475, Objectness Loss: 0.14633260667324066, Positive Objectness Loss: 0.5624297261238098, Class Loss: 0.05225149914622307,\n",
      "\tBatch: [150/188], Interval Loss: 0.3451, Epoch Loss: 0.3649, Lifetime Loss: 0.4020\n",
      "\t\tciou Loss: 0.1670583337545395, Objectness Loss: 0.14567022025585175, Positive Objectness Loss: 0.5627104043960571, Class Loss: 0.05219476297497749,\n",
      "\tBatch: [175/188], Interval Loss: 0.3704, Epoch Loss: 0.3678, Lifetime Loss: 0.4017\n",
      "\t\tciou Loss: 0.1682336926460266, Objectness Loss: 0.14701688289642334, Positive Objectness Loss: 0.5621141195297241, Class Loss: 0.05255510285496712,\n",
      "Epoch: [7/50], Avg Epoch Loss: 0.3679, Avg Lifetime Loss: 0.4014\n",
      "\tBatch: [25/188], Interval Loss: 0.3893, Epoch Loss: 0.3893, Lifetime Loss: 0.4011\n",
      "\t\tciou Loss: 0.17808015644550323, Objectness Loss: 0.15660682320594788, Positive Objectness Loss: 0.5581011176109314, Class Loss: 0.05456394702196121,\n",
      "\tBatch: [50/188], Interval Loss: 0.3436, Epoch Loss: 0.3736, Lifetime Loss: 0.4003\n",
      "\t\tciou Loss: 0.17187608778476715, Objectness Loss: 0.14932957291603088, Positive Objectness Loss: 0.5493137836456299, Class Loss: 0.05238877609372139,\n",
      "\tBatch: [75/188], Interval Loss: 0.3465, Epoch Loss: 0.3692, Lifetime Loss: 0.3996\n",
      "\t\tciou Loss: 0.16974158585071564, Objectness Loss: 0.14844462275505066, Positive Objectness Loss: 0.550805926322937, Class Loss: 0.05106094852089882,\n",
      "\tBatch: [100/188], Interval Loss: 0.3403, Epoch Loss: 0.3655, Lifetime Loss: 0.3988\n",
      "\t\tciou Loss: 0.16808658838272095, Objectness Loss: 0.14703121781349182, Positive Objectness Loss: 0.5526860356330872, Class Loss: 0.05034470558166504,\n",
      "\tBatch: [125/188], Interval Loss: 0.3390, Epoch Loss: 0.3629, Lifetime Loss: 0.3980\n",
      "\t\tciou Loss: 0.16726741194725037, Objectness Loss: 0.14586572349071503, Positive Objectness Loss: 0.552742600440979, Class Loss: 0.04977048560976982,\n",
      "\tBatch: [150/188], Interval Loss: 0.3505, Epoch Loss: 0.3632, Lifetime Loss: 0.3974\n",
      "\t\tciou Loss: 0.16725857555866241, Objectness Loss: 0.14598463475704193, Positive Objectness Loss: 0.555934488773346, Class Loss: 0.04993172362446785,\n",
      "\tBatch: [175/188], Interval Loss: 0.3470, Epoch Loss: 0.3628, Lifetime Loss: 0.3968\n",
      "\t\tciou Loss: 0.1672661155462265, Objectness Loss: 0.14575457572937012, Positive Objectness Loss: 0.5555197596549988, Class Loss: 0.049828361719846725,\n",
      "Epoch: [8/50], Avg Epoch Loss: 0.3636, Avg Lifetime Loss: 0.3967\n",
      "\tBatch: [25/188], Interval Loss: 0.3622, Epoch Loss: 0.3622, Lifetime Loss: 0.3961\n",
      "\t\tciou Loss: 0.16894102096557617, Objectness Loss: 0.14436988532543182, Positive Objectness Loss: 0.5492796897888184, Class Loss: 0.04884222149848938,\n",
      "\tBatch: [50/188], Interval Loss: 0.3516, Epoch Loss: 0.3639, Lifetime Loss: 0.3956\n",
      "\t\tciou Loss: 0.1692892611026764, Objectness Loss: 0.14546558260917664, Positive Objectness Loss: 0.5470492839813232, Class Loss: 0.04912740737199783,\n",
      "\tBatch: [75/188], Interval Loss: 0.3421, Epoch Loss: 0.3612, Lifetime Loss: 0.3950\n",
      "\t\tciou Loss: 0.16752158105373383, Objectness Loss: 0.14442585408687592, Positive Objectness Loss: 0.5487251281738281, Class Loss: 0.049281079322099686,\n",
      "\tBatch: [100/188], Interval Loss: 0.3412, Epoch Loss: 0.3597, Lifetime Loss: 0.3943\n",
      "\t\tciou Loss: 0.16621224582195282, Objectness Loss: 0.1445465236902237, Positive Objectness Loss: 0.5487886667251587, Class Loss: 0.048898205161094666,\n",
      "\tBatch: [125/188], Interval Loss: 0.3613, Epoch Loss: 0.3629, Lifetime Loss: 0.3940\n",
      "\t\tciou Loss: 0.16782186925411224, Objectness Loss: 0.146050363779068, Positive Objectness Loss: 0.5528025031089783, Class Loss: 0.04898003488779068,\n",
      "\tBatch: [150/188], Interval Loss: 0.3344, Epoch Loss: 0.3603, Lifetime Loss: 0.3933\n",
      "\t\tciou Loss: 0.1670309454202652, Objectness Loss: 0.14503023028373718, Positive Objectness Loss: 0.5513651371002197, Class Loss: 0.04828676953911781,\n",
      "\tBatch: [175/188], Interval Loss: 0.3401, Epoch Loss: 0.3594, Lifetime Loss: 0.3928\n",
      "\t\tciou Loss: 0.16653645038604736, Objectness Loss: 0.14485298097133636, Positive Objectness Loss: 0.5515902638435364, Class Loss: 0.048022158443927765,\n",
      "Epoch: [9/50], Avg Epoch Loss: 0.3601, Avg Lifetime Loss: 0.3926\n",
      "\tBatch: [25/188], Interval Loss: 0.3569, Epoch Loss: 0.3569, Lifetime Loss: 0.3921\n",
      "\t\tciou Loss: 0.16608886420726776, Objectness Loss: 0.14421463012695312, Positive Objectness Loss: 0.5523192882537842, Class Loss: 0.046612825244665146,\n",
      "\tBatch: [50/188], Interval Loss: 0.3343, Epoch Loss: 0.3524, Lifetime Loss: 0.3914\n",
      "\t\tciou Loss: 0.1632828712463379, Objectness Loss: 0.14226604998111725, Positive Objectness Loss: 0.5507566332817078, Class Loss: 0.04684501141309738,\n",
      "\tBatch: [75/188], Interval Loss: 0.3262, Epoch Loss: 0.3481, Lifetime Loss: 0.3907\n",
      "\t\tciou Loss: 0.16148442029953003, Objectness Loss: 0.1409372240304947, Positive Objectness Loss: 0.5502542853355408, Class Loss: 0.04565286636352539,\n",
      "\tBatch: [100/188], Interval Loss: 0.3618, Epoch Loss: 0.3551, Lifetime Loss: 0.3905\n",
      "\t\tciou Loss: 0.16483840346336365, Objectness Loss: 0.14366231858730316, Positive Objectness Loss: 0.5530219674110413, Class Loss: 0.04655921086668968,\n",
      "\tBatch: [125/188], Interval Loss: 0.3494, Epoch Loss: 0.3567, Lifetime Loss: 0.3901\n",
      "\t\tciou Loss: 0.16555248200893402, Objectness Loss: 0.14427067339420319, Positive Objectness Loss: 0.5516721606254578, Class Loss: 0.04688727483153343,\n",
      "\tBatch: [150/188], Interval Loss: 0.3411, Epoch Loss: 0.3564, Lifetime Loss: 0.3896\n",
      "\t\tciou Loss: 0.16560757160186768, Objectness Loss: 0.14397697150707245, Positive Objectness Loss: 0.5495662689208984, Class Loss: 0.04680819436907768,\n",
      "\tBatch: [175/188], Interval Loss: 0.3638, Epoch Loss: 0.3595, Lifetime Loss: 0.3895\n",
      "\t\tciou Loss: 0.16698892414569855, Objectness Loss: 0.14518395066261292, Positive Objectness Loss: 0.5491706132888794, Class Loss: 0.04734522104263306,\n",
      "Epoch: [10/50], Avg Epoch Loss: 0.3575, Avg Lifetime Loss: 0.3891\n",
      "\tBatch: [25/188], Interval Loss: 0.3699, Epoch Loss: 0.3699, Lifetime Loss: 0.3888\n",
      "\t\tciou Loss: 0.1705307960510254, Objectness Loss: 0.15012401342391968, Positive Objectness Loss: 0.5610107183456421, Class Loss: 0.04926589876413345,\n",
      "\tBatch: [50/188], Interval Loss: 0.3331, Epoch Loss: 0.3584, Lifetime Loss: 0.3883\n",
      "\t\tciou Loss: 0.16633154451847076, Objectness Loss: 0.14477235078811646, Positive Objectness Loss: 0.5506784319877625, Class Loss: 0.047306038439273834,\n",
      "\tBatch: [75/188], Interval Loss: 0.3353, Epoch Loss: 0.3552, Lifetime Loss: 0.3878\n",
      "\t\tciou Loss: 0.16521593928337097, Objectness Loss: 0.1430322527885437, Positive Objectness Loss: 0.5484133362770081, Class Loss: 0.04696310684084892,\n",
      "\tBatch: [100/188], Interval Loss: 0.3315, Epoch Loss: 0.3526, Lifetime Loss: 0.3872\n",
      "\t\tciou Loss: 0.16423483192920685, Objectness Loss: 0.14196649193763733, Positive Objectness Loss: 0.5442303419113159, Class Loss: 0.046430766582489014,\n",
      "\tBatch: [125/188], Interval Loss: 0.3465, Epoch Loss: 0.3542, Lifetime Loss: 0.3869\n",
      "\t\tciou Loss: 0.1645464152097702, Objectness Loss: 0.1430133879184723, Positive Objectness Loss: 0.5445692539215088, Class Loss: 0.046605609357357025,\n",
      "\tBatch: [150/188], Interval Loss: 0.3394, Epoch Loss: 0.3540, Lifetime Loss: 0.3865\n",
      "\t\tciou Loss: 0.16457130014896393, Objectness Loss: 0.14294105768203735, Positive Objectness Loss: 0.5439333915710449, Class Loss: 0.04646134376525879,\n",
      "\tBatch: [175/188], Interval Loss: 0.3528, Epoch Loss: 0.3558, Lifetime Loss: 0.3862\n",
      "\t\tciou Loss: 0.16575117409229279, Objectness Loss: 0.14378722012043, Positive Objectness Loss: 0.5451449155807495, Class Loss: 0.04626685008406639,\n",
      "Epoch: [11/50], Avg Epoch Loss: 0.3560, Avg Lifetime Loss: 0.3861\n",
      "\tBatch: [25/188], Interval Loss: 0.3424, Epoch Loss: 0.3424, Lifetime Loss: 0.3855\n",
      "\t\tciou Loss: 0.1602502316236496, Objectness Loss: 0.13733863830566406, Positive Objectness Loss: 0.5233416557312012, Class Loss: 0.044844850897789,\n",
      "\tBatch: [50/188], Interval Loss: 0.3460, Epoch Loss: 0.3510, Lifetime Loss: 0.3852\n",
      "\t\tciou Loss: 0.16351772844791412, Objectness Loss: 0.14185117185115814, Positive Objectness Loss: 0.5322114825248718, Class Loss: 0.045613955706357956,\n",
      "\tBatch: [75/188], Interval Loss: 0.3400, Epoch Loss: 0.3519, Lifetime Loss: 0.3849\n",
      "\t\tciou Loss: 0.16443225741386414, Objectness Loss: 0.141944020986557, Positive Objectness Loss: 0.5299522280693054, Class Loss: 0.04548211768269539,\n",
      "\tBatch: [100/188], Interval Loss: 0.3535, Epoch Loss: 0.3558, Lifetime Loss: 0.3847\n",
      "\t\tciou Loss: 0.16667567193508148, Objectness Loss: 0.1435866802930832, Positive Objectness Loss: 0.5347020626068115, Class Loss: 0.04549160599708557,\n",
      "\tBatch: [125/188], Interval Loss: 0.3464, Epoch Loss: 0.3566, Lifetime Loss: 0.3844\n",
      "\t\tciou Loss: 0.16663758456707, Objectness Loss: 0.1441989243030548, Positive Objectness Loss: 0.5343149304389954, Class Loss: 0.045802462846040726,\n",
      "\tBatch: [150/188], Interval Loss: 0.3340, Epoch Loss: 0.3551, Lifetime Loss: 0.3840\n",
      "\t\tciou Loss: 0.16596657037734985, Objectness Loss: 0.14339417219161987, Positive Objectness Loss: 0.5345673561096191, Class Loss: 0.0457366406917572,\n",
      "\tBatch: [175/188], Interval Loss: 0.3438, Epoch Loss: 0.3554, Lifetime Loss: 0.3837\n",
      "\t\tciou Loss: 0.16620083153247833, Objectness Loss: 0.14356616139411926, Positive Objectness Loss: 0.5365994572639465, Class Loss: 0.04567602649331093,\n",
      "Epoch: [12/50], Avg Epoch Loss: 0.3534, Avg Lifetime Loss: 0.3834\n",
      "\tBatch: [25/188], Interval Loss: 0.3561, Epoch Loss: 0.3561, Lifetime Loss: 0.3830\n",
      "\t\tciou Loss: 0.16681143641471863, Objectness Loss: 0.14370834827423096, Positive Objectness Loss: 0.5468569397926331, Class Loss: 0.0455445758998394,\n",
      "\tBatch: [50/188], Interval Loss: 0.3425, Epoch Loss: 0.3561, Lifetime Loss: 0.3828\n",
      "\t\tciou Loss: 0.16795648634433746, Objectness Loss: 0.1434604972600937, Positive Objectness Loss: 0.5480443239212036, Class Loss: 0.04471004381775856,\n",
      "\tBatch: [75/188], Interval Loss: 0.3381, Epoch Loss: 0.3546, Lifetime Loss: 0.3824\n",
      "\t\tciou Loss: 0.16687245666980743, Objectness Loss: 0.14320814609527588, Positive Objectness Loss: 0.5419716835021973, Class Loss: 0.04456833377480507,\n",
      "\tBatch: [100/188], Interval Loss: 0.3305, Epoch Loss: 0.3519, Lifetime Loss: 0.3820\n",
      "\t\tciou Loss: 0.16527657210826874, Objectness Loss: 0.14197556674480438, Positive Objectness Loss: 0.5403833389282227, Class Loss: 0.04468381777405739,\n",
      "\tBatch: [125/188], Interval Loss: 0.3271, Epoch Loss: 0.3496, Lifetime Loss: 0.3816\n",
      "\t\tciou Loss: 0.16400790214538574, Objectness Loss: 0.14104078710079193, Positive Objectness Loss: 0.5386767387390137, Class Loss: 0.04455883800983429,\n",
      "\tBatch: [150/188], Interval Loss: 0.3449, Epoch Loss: 0.3511, Lifetime Loss: 0.3813\n",
      "\t\tciou Loss: 0.16459493339061737, Objectness Loss: 0.14168459177017212, Positive Objectness Loss: 0.5395821928977966, Class Loss: 0.044829003512859344,\n",
      "\tBatch: [175/188], Interval Loss: 0.3404, Epoch Loss: 0.3515, Lifetime Loss: 0.3811\n",
      "\t\tciou Loss: 0.16470341384410858, Objectness Loss: 0.14187099039554596, Positive Objectness Loss: 0.5399540066719055, Class Loss: 0.044951602816581726,\n",
      "Epoch: [13/50], Avg Epoch Loss: 0.3515, Avg Lifetime Loss: 0.3809\n",
      "\tBatch: [25/188], Interval Loss: 0.3373, Epoch Loss: 0.3373, Lifetime Loss: 0.3804\n",
      "\t\tciou Loss: 0.15869712829589844, Objectness Loss: 0.13490305840969086, Positive Objectness Loss: 0.5147262215614319, Class Loss: 0.043740496039390564,\n",
      "\tBatch: [50/188], Interval Loss: 0.3489, Epoch Loss: 0.3499, Lifetime Loss: 0.3803\n",
      "\t\tciou Loss: 0.16411904990673065, Objectness Loss: 0.14089655876159668, Positive Objectness Loss: 0.5281720161437988, Class Loss: 0.044854696840047836,\n",
      "\tBatch: [75/188], Interval Loss: 0.3478, Epoch Loss: 0.3538, Lifetime Loss: 0.3801\n",
      "\t\tciou Loss: 0.1657433658838272, Objectness Loss: 0.1423381268978119, Positive Objectness Loss: 0.5292338728904724, Class Loss: 0.045698512345552444,\n",
      "\tBatch: [100/188], Interval Loss: 0.3338, Epoch Loss: 0.3521, Lifetime Loss: 0.3798\n",
      "\t\tciou Loss: 0.1651606559753418, Objectness Loss: 0.1419331580400467, Positive Objectness Loss: 0.5289426445960999, Class Loss: 0.04505077004432678,\n",
      "\tBatch: [125/188], Interval Loss: 0.3402, Epoch Loss: 0.3525, Lifetime Loss: 0.3795\n",
      "\t\tciou Loss: 0.16508404910564423, Objectness Loss: 0.1422874480485916, Positive Objectness Loss: 0.5325994491577148, Class Loss: 0.0451083667576313,\n",
      "\tBatch: [150/188], Interval Loss: 0.3279, Epoch Loss: 0.3506, Lifetime Loss: 0.3791\n",
      "\t\tciou Loss: 0.1641516238451004, Objectness Loss: 0.14159588515758514, Positive Objectness Loss: 0.532752513885498, Class Loss: 0.04482831433415413,\n",
      "\tBatch: [175/188], Interval Loss: 0.3348, Epoch Loss: 0.3502, Lifetime Loss: 0.3788\n",
      "\t\tciou Loss: 0.16403521597385406, Objectness Loss: 0.14176957309246063, Positive Objectness Loss: 0.5358734726905823, Class Loss: 0.044425345957279205,\n",
      "Epoch: [14/50], Avg Epoch Loss: 0.3499, Avg Lifetime Loss: 0.3787\n",
      "\tBatch: [25/188], Interval Loss: 0.3530, Epoch Loss: 0.3530, Lifetime Loss: 0.3784\n",
      "\t\tciou Loss: 0.16645413637161255, Objectness Loss: 0.14116758108139038, Positive Objectness Loss: 0.5331557393074036, Class Loss: 0.04542029649019241,\n",
      "\tBatch: [50/188], Interval Loss: 0.3406, Epoch Loss: 0.3536, Lifetime Loss: 0.3782\n",
      "\t\tciou Loss: 0.1663014143705368, Objectness Loss: 0.14246346056461334, Positive Objectness Loss: 0.5395245552062988, Class Loss: 0.044852592051029205,\n",
      "\tBatch: [75/188], Interval Loss: 0.3384, Epoch Loss: 0.3531, Lifetime Loss: 0.3780\n",
      "\t\tciou Loss: 0.1661316156387329, Objectness Loss: 0.14255428314208984, Positive Objectness Loss: 0.5356085300445557, Class Loss: 0.04438125714659691,\n",
      "\tBatch: [100/188], Interval Loss: 0.3294, Epoch Loss: 0.3505, Lifetime Loss: 0.3776\n",
      "\t\tciou Loss: 0.16455793380737305, Objectness Loss: 0.14144989848136902, Positive Objectness Loss: 0.5330955982208252, Class Loss: 0.044470205903053284,\n",
      "\tBatch: [125/188], Interval Loss: 0.3335, Epoch Loss: 0.3498, Lifetime Loss: 0.3774\n",
      "\t\tciou Loss: 0.16424711048603058, Objectness Loss: 0.14118266105651855, Positive Objectness Loss: 0.5320051312446594, Class Loss: 0.044332653284072876,\n",
      "\tBatch: [150/188], Interval Loss: 0.3153, Epoch Loss: 0.3461, Lifetime Loss: 0.3769\n",
      "\t\tciou Loss: 0.1624482423067093, Objectness Loss: 0.13992805778980255, Positive Objectness Loss: 0.5326153635978699, Class Loss: 0.04376205801963806,\n",
      "\tBatch: [175/188], Interval Loss: 0.3362, Epoch Loss: 0.3466, Lifetime Loss: 0.3767\n",
      "\t\tciou Loss: 0.16305851936340332, Objectness Loss: 0.13984084129333496, Positive Objectness Loss: 0.5325519442558289, Class Loss: 0.04373127222061157,\n",
      "Epoch: [15/50], Avg Epoch Loss: 0.3474, Avg Lifetime Loss: 0.3766\n",
      "\tBatch: [25/188], Interval Loss: 0.3499, Epoch Loss: 0.3499, Lifetime Loss: 0.3764\n",
      "\t\tciou Loss: 0.16421087086200714, Objectness Loss: 0.14149342477321625, Positive Objectness Loss: 0.5189758539199829, Class Loss: 0.044178277254104614,\n",
      "\tBatch: [50/188], Interval Loss: 0.3441, Epoch Loss: 0.3538, Lifetime Loss: 0.3762\n",
      "\t\tciou Loss: 0.166366308927536, Objectness Loss: 0.1428866684436798, Positive Objectness Loss: 0.5229021906852722, Class Loss: 0.04455418884754181,\n",
      "\tBatch: [75/188], Interval Loss: 0.3233, Epoch Loss: 0.3480, Lifetime Loss: 0.3759\n",
      "\t\tciou Loss: 0.1637989729642868, Objectness Loss: 0.14033003151416779, Positive Objectness Loss: 0.521759033203125, Class Loss: 0.04391280934214592,\n",
      "\tBatch: [100/188], Interval Loss: 0.3304, Epoch Loss: 0.3469, Lifetime Loss: 0.3756\n",
      "\t\tciou Loss: 0.16332611441612244, Objectness Loss: 0.1399177461862564, Positive Objectness Loss: 0.5261402726173401, Class Loss: 0.043690524995326996,\n",
      "\tBatch: [125/188], Interval Loss: 0.3392, Epoch Loss: 0.3481, Lifetime Loss: 0.3754\n",
      "\t\tciou Loss: 0.1637895107269287, Objectness Loss: 0.1407070755958557, Positive Objectness Loss: 0.5266727209091187, Class Loss: 0.04359295964241028,\n",
      "\tBatch: [150/188], Interval Loss: 0.3240, Epoch Loss: 0.3462, Lifetime Loss: 0.3751\n",
      "\t\tciou Loss: 0.1629304587841034, Objectness Loss: 0.13992726802825928, Positive Objectness Loss: 0.527694582939148, Class Loss: 0.04338567703962326,\n",
      "\tBatch: [175/188], Interval Loss: 0.3282, Epoch Loss: 0.3455, Lifetime Loss: 0.3748\n",
      "\t\tciou Loss: 0.1626792848110199, Objectness Loss: 0.1395118683576584, Positive Objectness Loss: 0.5283815860748291, Class Loss: 0.04335620626807213,\n",
      "Epoch: [16/50], Avg Epoch Loss: 0.3457, Avg Lifetime Loss: 0.3747\n",
      "\tBatch: [25/188], Interval Loss: 0.3250, Epoch Loss: 0.3250, Lifetime Loss: 0.3743\n",
      "\t\tciou Loss: 0.15353438258171082, Objectness Loss: 0.1297159343957901, Positive Objectness Loss: 0.5346581339836121, Class Loss: 0.04179324209690094,\n",
      "\tBatch: [50/188], Interval Loss: 0.3288, Epoch Loss: 0.3333, Lifetime Loss: 0.3740\n",
      "\t\tciou Loss: 0.15758612751960754, Objectness Loss: 0.133586585521698, Positive Objectness Loss: 0.5329538583755493, Class Loss: 0.04216131567955017,\n",
      "\tBatch: [75/188], Interval Loss: 0.3389, Epoch Loss: 0.3396, Lifetime Loss: 0.3738\n",
      "\t\tciou Loss: 0.16019964218139648, Objectness Loss: 0.13638272881507874, Positive Objectness Loss: 0.5320641398429871, Class Loss: 0.04305010288953781,\n",
      "\tBatch: [100/188], Interval Loss: 0.3317, Epoch Loss: 0.3409, Lifetime Loss: 0.3736\n",
      "\t\tciou Loss: 0.16093499958515167, Objectness Loss: 0.13699156045913696, Positive Objectness Loss: 0.5309131741523743, Class Loss: 0.043022871017456055,\n",
      "\tBatch: [125/188], Interval Loss: 0.3311, Epoch Loss: 0.3416, Lifetime Loss: 0.3733\n",
      "\t\tciou Loss: 0.1611739844083786, Objectness Loss: 0.1374628245830536, Positive Objectness Loss: 0.5295321941375732, Class Loss: 0.042988404631614685,\n",
      "\tBatch: [150/188], Interval Loss: 0.3239, Epoch Loss: 0.3408, Lifetime Loss: 0.3731\n",
      "\t\tciou Loss: 0.16102127730846405, Objectness Loss: 0.13705095648765564, Positive Objectness Loss: 0.5265467166900635, Class Loss: 0.042759962379932404,\n",
      "\tBatch: [175/188], Interval Loss: 0.3420, Epoch Loss: 0.3429, Lifetime Loss: 0.3729\n",
      "\t\tciou Loss: 0.16194511950016022, Objectness Loss: 0.13788345456123352, Positive Objectness Loss: 0.5250313878059387, Class Loss: 0.04311241954565048,\n",
      "Epoch: [17/50], Avg Epoch Loss: 0.3438, Avg Lifetime Loss: 0.3729\n",
      "\tBatch: [25/188], Interval Loss: 0.3445, Epoch Loss: 0.3445, Lifetime Loss: 0.3726\n",
      "\t\tciou Loss: 0.1635562926530838, Objectness Loss: 0.13765303790569305, Positive Objectness Loss: 0.5158034563064575, Class Loss: 0.04328659176826477,\n",
      "\tBatch: [50/188], Interval Loss: 0.3125, Epoch Loss: 0.3350, Lifetime Loss: 0.3723\n",
      "\t\tciou Loss: 0.15866301953792572, Objectness Loss: 0.13429351150989532, Positive Objectness Loss: 0.5105844736099243, Class Loss: 0.04199527949094772,\n",
      "\tBatch: [75/188], Interval Loss: 0.3434, Epoch Loss: 0.3423, Lifetime Loss: 0.3722\n",
      "\t\tciou Loss: 0.16179342567920685, Objectness Loss: 0.13736452162265778, Positive Objectness Loss: 0.5155505537986755, Class Loss: 0.04310483857989311,\n",
      "\tBatch: [100/188], Interval Loss: 0.3283, Epoch Loss: 0.3421, Lifetime Loss: 0.3719\n",
      "\t\tciou Loss: 0.16199426352977753, Objectness Loss: 0.13703124225139618, Positive Objectness Loss: 0.5174014568328857, Class Loss: 0.043037060648202896,\n",
      "\tBatch: [125/188], Interval Loss: 0.3237, Epoch Loss: 0.3410, Lifetime Loss: 0.3717\n",
      "\t\tciou Loss: 0.16126851737499237, Objectness Loss: 0.13668952882289886, Positive Objectness Loss: 0.5191747546195984, Class Loss: 0.04303152114152908,\n",
      "\tBatch: [150/188], Interval Loss: 0.3200, Epoch Loss: 0.3396, Lifetime Loss: 0.3714\n",
      "\t\tciou Loss: 0.16086454689502716, Objectness Loss: 0.1362355351448059, Positive Objectness Loss: 0.5207394361495972, Class Loss: 0.04253438860177994,\n",
      "\tBatch: [175/188], Interval Loss: 0.3407, Epoch Loss: 0.3417, Lifetime Loss: 0.3712\n",
      "\t\tciou Loss: 0.1621181219816208, Objectness Loss: 0.13694091141223907, Positive Objectness Loss: 0.5219007730484009, Class Loss: 0.042655300348997116,\n",
      "Epoch: [18/50], Avg Epoch Loss: 0.3418, Avg Lifetime Loss: 0.3711\n",
      "\tBatch: [25/188], Interval Loss: 0.3434, Epoch Loss: 0.3434, Lifetime Loss: 0.3709\n",
      "\t\tciou Loss: 0.16437244415283203, Objectness Loss: 0.13632413744926453, Positive Objectness Loss: 0.5097674131393433, Class Loss: 0.042657606303691864,\n",
      "\tBatch: [50/188], Interval Loss: 0.3177, Epoch Loss: 0.3370, Lifetime Loss: 0.3706\n",
      "\t\tciou Loss: 0.1609681099653244, Objectness Loss: 0.1340872049331665, Positive Objectness Loss: 0.5146088600158691, Class Loss: 0.04196199029684067,\n",
      "\tBatch: [75/188], Interval Loss: 0.3387, Epoch Loss: 0.3420, Lifetime Loss: 0.3705\n",
      "\t\tciou Loss: 0.16375255584716797, Objectness Loss: 0.13608084619045258, Positive Objectness Loss: 0.5171341896057129, Class Loss: 0.04219183325767517,\n",
      "\tBatch: [100/188], Interval Loss: 0.3258, Epoch Loss: 0.3412, Lifetime Loss: 0.3703\n",
      "\t\tciou Loss: 0.16310864686965942, Objectness Loss: 0.13550426065921783, Positive Objectness Loss: 0.5115150213241577, Class Loss: 0.04262806102633476,\n",
      "\tBatch: [125/188], Interval Loss: 0.3153, Epoch Loss: 0.3386, Lifetime Loss: 0.3700\n",
      "\t\tciou Loss: 0.16160805523395538, Objectness Loss: 0.13481104373931885, Positive Objectness Loss: 0.5122799277305603, Class Loss: 0.04217015951871872,\n",
      "\tBatch: [150/188], Interval Loss: 0.3294, Epoch Loss: 0.3393, Lifetime Loss: 0.3698\n",
      "\t\tciou Loss: 0.16172091662883759, Objectness Loss: 0.13521336019039154, Positive Objectness Loss: 0.5148609280586243, Class Loss: 0.04231720417737961,\n",
      "\tBatch: [175/188], Interval Loss: 0.3316, Epoch Loss: 0.3401, Lifetime Loss: 0.3696\n",
      "\t\tciou Loss: 0.1620054990053177, Objectness Loss: 0.13549044728279114, Positive Objectness Loss: 0.5147755742073059, Class Loss: 0.04255586490035057,\n",
      "Epoch: [19/50], Avg Epoch Loss: 0.3396, Avg Lifetime Loss: 0.3695\n",
      "\tBatch: [25/188], Interval Loss: 0.3261, Epoch Loss: 0.3261, Lifetime Loss: 0.3692\n",
      "\t\tciou Loss: 0.1556463986635208, Objectness Loss: 0.1299740970134735, Positive Objectness Loss: 0.51125168800354, Class Loss: 0.04046105593442917,\n",
      "\tBatch: [50/188], Interval Loss: 0.3300, Epoch Loss: 0.3345, Lifetime Loss: 0.3690\n",
      "\t\tciou Loss: 0.15984000265598297, Objectness Loss: 0.1326715499162674, Positive Objectness Loss: 0.5150735378265381, Class Loss: 0.0419466570019722,\n",
      "\tBatch: [75/188], Interval Loss: 0.3228, Epoch Loss: 0.3349, Lifetime Loss: 0.3688\n",
      "\t\tciou Loss: 0.16001597046852112, Objectness Loss: 0.13311859965324402, Positive Objectness Loss: 0.5154640078544617, Class Loss: 0.04174606502056122,\n",
      "\tBatch: [100/188], Interval Loss: 0.3203, Epoch Loss: 0.3344, Lifetime Loss: 0.3685\n",
      "\t\tciou Loss: 0.160202756524086, Objectness Loss: 0.1325812041759491, Positive Objectness Loss: 0.5127069354057312, Class Loss: 0.04165690019726753,\n",
      "\tBatch: [125/188], Interval Loss: 0.3173, Epoch Loss: 0.3336, Lifetime Loss: 0.3683\n",
      "\t\tciou Loss: 0.1597146838903427, Objectness Loss: 0.13223563134670258, Positive Objectness Loss: 0.5126591920852661, Class Loss: 0.04161057248711586,\n",
      "\tBatch: [150/188], Interval Loss: 0.3330, Epoch Loss: 0.3357, Lifetime Loss: 0.3681\n",
      "\t\tciou Loss: 0.16064421832561493, Objectness Loss: 0.13318346440792084, Positive Objectness Loss: 0.5143408179283142, Class Loss: 0.04183724522590637,\n",
      "\tBatch: [175/188], Interval Loss: 0.3294, Epoch Loss: 0.3367, Lifetime Loss: 0.3679\n",
      "\t\tciou Loss: 0.16111399233341217, Objectness Loss: 0.13354673981666565, Positive Objectness Loss: 0.513458788394928, Class Loss: 0.04199222847819328,\n",
      "Epoch: [20/50], Avg Epoch Loss: 0.3371, Avg Lifetime Loss: 0.3679\n",
      "\tBatch: [25/188], Interval Loss: 0.3450, Epoch Loss: 0.3450, Lifetime Loss: 0.3677\n",
      "\t\tciou Loss: 0.1653883308172226, Objectness Loss: 0.1359749287366867, Positive Objectness Loss: 0.5004408359527588, Class Loss: 0.043605197221040726,\n",
      "\tBatch: [50/188], Interval Loss: 0.3101, Epoch Loss: 0.3340, Lifetime Loss: 0.3674\n",
      "\t\tciou Loss: 0.16019092500209808, Objectness Loss: 0.1320589780807495, Positive Objectness Loss: 0.49798664450645447, Class Loss: 0.04173078387975693,\n",
      "\tBatch: [75/188], Interval Loss: 0.3194, Epoch Loss: 0.3334, Lifetime Loss: 0.3672\n",
      "\t\tciou Loss: 0.15986600518226624, Objectness Loss: 0.13131798803806305, Positive Objectness Loss: 0.49457380175590515, Class Loss: 0.04219827428460121,\n",
      "\tBatch: [100/188], Interval Loss: 0.3263, Epoch Loss: 0.3349, Lifetime Loss: 0.3670\n",
      "\t\tciou Loss: 0.1606658697128296, Objectness Loss: 0.13193891942501068, Positive Objectness Loss: 0.49613460898399353, Class Loss: 0.04225141555070877,\n",
      "\tBatch: [125/188], Interval Loss: 0.3066, Epoch Loss: 0.3317, Lifetime Loss: 0.3667\n",
      "\t\tciou Loss: 0.1594449281692505, Objectness Loss: 0.13073976337909698, Positive Objectness Loss: 0.5014996528625488, Class Loss: 0.04150829836726189,\n",
      "\tBatch: [150/188], Interval Loss: 0.3230, Epoch Loss: 0.3324, Lifetime Loss: 0.3665\n",
      "\t\tciou Loss: 0.15959709882736206, Objectness Loss: 0.1311323046684265, Positive Objectness Loss: 0.5040804743766785, Class Loss: 0.04166165366768837,\n",
      "\tBatch: [175/188], Interval Loss: 0.3348, Epoch Loss: 0.3346, Lifetime Loss: 0.3664\n",
      "\t\tciou Loss: 0.16084401309490204, Objectness Loss: 0.13197162747383118, Positive Objectness Loss: 0.505427360534668, Class Loss: 0.0418221652507782,\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "training_lifetime_loss = 0.0\n",
    "training_lifetime_batch = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_obj_loss = []\n",
    "    epoch_cls_loss = []\n",
    "    epoch_ciou_loss = []\n",
    "    epoch_pos_obj_loss = []\n",
    "\n",
    "\n",
    "    model.train() \n",
    "    epoch_loss = 0.0\n",
    "    batch_interval_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(trash_dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss_item = loss['total']\n",
    "        \n",
    "        epoch_obj_loss.append(loss['objectness'])\n",
    "        epoch_cls_loss.append(loss['classification'])\n",
    "        epoch_ciou_loss.append(loss['ciou'])\n",
    "        try:\n",
    "            epoch_pos_obj_loss.append(loss['positive_objectness'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Check for invalid loss values\n",
    "        if torch.isnan(loss_item) or torch.isinf(loss_item):\n",
    "            print(f\"Warning: Invalid loss detected at epoch {epoch+1}, batch {i}\")\n",
    "            print(f\"Loss value: {loss_item.item()}\")\n",
    "            continue  \n",
    "        \n",
    "        loss_item.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses\n",
    "        loss_item = loss_item.item()\n",
    "        epoch_loss += loss_item\n",
    "        batch_interval_loss += loss_item\n",
    "        training_lifetime_loss += loss_item\n",
    "        num_batches += 1\n",
    "        training_lifetime_batch += 1\n",
    "        \n",
    "        # Print batch interval statistics\n",
    "        if i % (batch_interval) == 0 and i != 0:\n",
    "            avg_interval_loss = batch_interval_loss / (batch_interval+1)  # Fixed division\n",
    "            avg_epoch_loss_so_far = epoch_loss / num_batches\n",
    "            avg_lifetime_loss = training_lifetime_loss / training_lifetime_batch\n",
    "            \n",
    "            print(f'\\tBatch: [{i}/{len(trash_dataloader)}], '\n",
    "                  f'Interval Loss: {avg_interval_loss:.4f}, '\n",
    "                  f'Epoch Loss: {avg_epoch_loss_so_far:.4f}, '\n",
    "                  f'Lifetime Loss: {avg_lifetime_loss:.4f}')\n",
    "            print(f'\\t\\tciou Loss: {sum(epoch_ciou_loss) / len(epoch_ciou_loss)}, Objectness Loss: {sum(epoch_obj_loss) / len(epoch_obj_loss)}, Positive Objectness Loss: {sum(epoch_pos_obj_loss) / len(epoch_pos_obj_loss)}, Class Loss: {sum(epoch_cls_loss) / len(epoch_cls_loss)},')\n",
    "            \n",
    "            batch_interval_loss = 0.0\n",
    "    \n",
    "    # Epoch summary\n",
    "    if num_batches > 0:\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        avg_lifetime_loss = training_lifetime_loss / training_lifetime_batch\n",
    "        \n",
    "        print(f'Epoch: [{epoch+1}/{num_epochs}], '\n",
    "              f'Avg Epoch Loss: {avg_epoch_loss:.4f}, '\n",
    "              f'Avg Lifetime Loss: {avg_lifetime_loss:.4f}')\n",
    "        \n",
    "        if (epoch + 1) % 25 == 0: \n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_epoch_loss,\n",
    "                'lifetime_loss': avg_lifetime_loss\n",
    "            }\n",
    "            torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "            print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Final average lifetime loss: {training_lifetime_loss / training_lifetime_batch:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

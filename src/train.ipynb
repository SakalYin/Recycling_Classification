{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4808c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detector_model.model import ObjectDetectionModel\n",
    "from models.detector_model.processor import TrainingProcessor\n",
    "from models.detector_model.data_utils import TrainingDataset, COCOProcessor\n",
    "from models.detector_model.loss import ObjectDetectionLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "grouped_classes = {\n",
    "        \"Metal\": [\n",
    "            \"Metal bottle cap\", \"Metal lid\", \"Drink can\", \"Pop tab\", \"Scrap metal\",\n",
    "            \"Food Can\", \"Aluminium blister pack\", \"Aluminium foil\", \"Aerosol\"\n",
    "        ],\n",
    "        \"Plastic\": [\n",
    "            \"Plastic bottle cap\", \"Other plastic wrapper\", \"Six pack rings\",\n",
    "            \"Single-use carrier bag\", \"Plastic straw\", \"Plastic glooves\",\n",
    "            \"Plastic utensils\", \"Disposable plastic cup\", \"Other plastic bottle\",\n",
    "            \"Tupperware\", \"Spread tub\", \"Garbage bag\", \"Other plastic container\",\n",
    "            \"Other plastic\", \"Rope & strings\", \"Other plastic cup\", \"Plastic film\",\n",
    "            \"Polypropylene bag\", \"Plastic lid\", \"Clear plastic bottle\", \"Squeezable tube\",\n",
    "            \"Carded blister pack\", \"Crisp packet\", \"Meal carton\"\n",
    "        ],\n",
    "        \"Paper\": [\n",
    "            \"Paper cup\", \"Paper bag\", \"Normal paper\", \"Paper straw\", \"Tissues\",\n",
    "            \"Toilet tube\", \"Wrapping paper\", \"Pizza box\", \"Magazine paper\",\n",
    "            \"Corrugated carton\", \"Egg carton\", \"Other carton\", \"Drink carton\"\n",
    "        ],\n",
    "        \"Glass\": [\n",
    "            \"Glass jar\", \"Glass bottle\", \"Glass cup\", \"Broken glass\"\n",
    "        ],\n",
    "        \"Waste\": [\n",
    "            \"Cigarette\", \"Food waste\", \"Foam cup\",\n",
    "            \"Disposable food container\", \"Foam food container\",\n",
    "            \"Shoe\", \"Unlabeled litter\", \"Styrofoam piece\"\n",
    "        ],\n",
    "        \"Battery\": [\n",
    "            \"Battery\"\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0db955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "==================================================\n",
      "Total parameters:      390,700\n",
      "Trainable parameters:  390,700\n",
      "Non-trainable params:  0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model = ObjectDetectionModel(num_classes=len(grouped_classes), num_anchors=4, grid_size=4)\n",
    "model.count_parameters()\n",
    "coco_processor = COCOProcessor(classes=grouped_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d701f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_trash = coco_processor.extract_annotations(\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/Dataset/Trash Detection.v14i.coco/train/_annotations.coco.json',\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/Dataset/Trash Detection.v14i.coco/train',\n",
    "    convert=False\n",
    ")\n",
    "\n",
    "extracted_taco = coco_processor.extract_annotations(\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/TACO/data/annotations.json',\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/TACO/data',\n",
    "    convert=True\n",
    ")\n",
    "\n",
    "classes_names_trash = []\n",
    "for label in extracted_trash:\n",
    "    classes_names_trash.extend(label['Class'])\n",
    "classes_names_trash = list(set(classes_names_trash))\n",
    "\n",
    "classes_names_taco = []\n",
    "for label in extracted_taco:\n",
    "    classes_names_taco.extend(label['Class'])\n",
    "classes_names_taco = list(set(classes_names_taco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef08bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "classes = [item for item, value in grouped_classes.items()] # ['Metal', 'Plastic', 'Paper', 'Glass', 'Waste', 'Battery']\n",
    "\n",
    "processor = TrainingProcessor(\n",
    "    input_size=448,\n",
    "    grid_size=model.grid_size,\n",
    "    num_anchors=model.num_anchors,\n",
    "    classes=classes,\n",
    ")\n",
    "\n",
    "trash_dataset = TrainingDataset(data_json=extracted_trash, processor=processor, is_training=False)\n",
    "trash_dataloader = DataLoader(trash_dataset, batch_size=25, shuffle=True)\n",
    "\n",
    "# image_tensor, target_tensor, anchor_pose = processor.process_training_sample(\n",
    "#     extracted_trash[90], apply_augmentation=False, get_anchors=True)\n",
    "\n",
    "# processor.visualize_training_sample(\n",
    "#     image_tensor, target_tensor, anchor_pose,)\n",
    "\n",
    "# bboxes = processor.convert_yolo_output_to_bboxes(target_tensor)\n",
    "# processor.draw_bbox_on_image(image_tensor, bboxes, tensor=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ceb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = ObjectDetectionLoss(processor=processor, classes_alpha=[0.3,0.4,0.3,0.1,0.3,0.2])\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,           # learning rate\n",
    "    betas=(0.9, 0.999),# beta1 and beta2 for momentum estimates\n",
    "    eps=1e-8,          # small constant for numerical stability\n",
    "    weight_decay=0     # L2 regularization\n",
    ")\n",
    "\n",
    "num_epochs = 50\n",
    "batch_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc997375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: [1/240], Batch Loss: 0.0000, Overall Loss: 0.0000\n",
      "\tBatch: [2/240], Batch Loss: 0.0230, Overall Loss: 0.0115\n",
      "\tBatch: [3/240], Batch Loss: 0.0000, Overall Loss: 0.0077\n",
      "\tBatch: [4/240], Batch Loss: 0.0113, Overall Loss: 0.0086\n",
      "\tBatch: [5/240], Batch Loss: 0.0000, Overall Loss: 0.0069\n",
      "\tBatch: [6/240], Batch Loss: 0.0000, Overall Loss: 0.0057\n",
      "\tBatch: [7/240], Batch Loss: 0.0238, Overall Loss: 0.0083\n",
      "\tBatch: [8/240], Batch Loss: 0.0000, Overall Loss: 0.0073\n",
      "\tBatch: [9/240], Batch Loss: 0.0000, Overall Loss: 0.0065\n",
      "\tBatch: [10/240], Batch Loss: 0.0000, Overall Loss: 0.0058\n",
      "\tBatch: [11/240], Batch Loss: 0.0499, Overall Loss: 0.0098\n",
      "\tBatch: [12/240], Batch Loss: 0.0000, Overall Loss: 0.0090\n",
      "\tBatch: [13/240], Batch Loss: 0.0227, Overall Loss: 0.0101\n",
      "\tBatch: [14/240], Batch Loss: 0.0000, Overall Loss: 0.0093\n",
      "\tBatch: [15/240], Batch Loss: 0.0000, Overall Loss: 0.0087\n",
      "\tBatch: [16/240], Batch Loss: 0.0000, Overall Loss: 0.0082\n",
      "\tBatch: [17/240], Batch Loss: 0.0000, Overall Loss: 0.0077\n",
      "\tBatch: [18/240], Batch Loss: 0.0000, Overall Loss: 0.0073\n",
      "\tBatch: [19/240], Batch Loss: 0.0000, Overall Loss: 0.0069\n",
      "\tBatch: [20/240], Batch Loss: 0.0000, Overall Loss: 0.0065\n",
      "\tBatch: [21/240], Batch Loss: 0.0000, Overall Loss: 0.0062\n",
      "\tBatch: [22/240], Batch Loss: 0.0116, Overall Loss: 0.0065\n",
      "\tBatch: [23/240], Batch Loss: 0.0000, Overall Loss: 0.0062\n",
      "\tBatch: [24/240], Batch Loss: 0.0000, Overall Loss: 0.0059\n",
      "\tBatch: [25/240], Batch Loss: 0.0117, Overall Loss: 0.0062\n",
      "\tBatch: [26/240], Batch Loss: 0.0000, Overall Loss: 0.0059\n",
      "\tBatch: [27/240], Batch Loss: 0.0000, Overall Loss: 0.0057\n",
      "\tBatch: [28/240], Batch Loss: 0.0000, Overall Loss: 0.0055\n",
      "\tBatch: [29/240], Batch Loss: 0.0000, Overall Loss: 0.0053\n",
      "\tBatch: [30/240], Batch Loss: 0.0000, Overall Loss: 0.0051\n",
      "\tBatch: [31/240], Batch Loss: 0.0000, Overall Loss: 0.0050\n",
      "\tBatch: [32/240], Batch Loss: 0.0000, Overall Loss: 0.0048\n",
      "\tBatch: [33/240], Batch Loss: 0.0000, Overall Loss: 0.0047\n",
      "\tBatch: [34/240], Batch Loss: 0.0114, Overall Loss: 0.0049\n",
      "\tBatch: [35/240], Batch Loss: 0.0000, Overall Loss: 0.0047\n",
      "\tBatch: [36/240], Batch Loss: 0.0000, Overall Loss: 0.0046\n",
      "\tBatch: [37/240], Batch Loss: 0.0000, Overall Loss: 0.0045\n",
      "\tBatch: [38/240], Batch Loss: 0.0115, Overall Loss: 0.0047\n",
      "\tBatch: [39/240], Batch Loss: 0.0000, Overall Loss: 0.0045\n",
      "\tBatch: [40/240], Batch Loss: 0.0000, Overall Loss: 0.0044\n",
      "\tBatch: [41/240], Batch Loss: 0.0000, Overall Loss: 0.0043\n",
      "\tBatch: [42/240], Batch Loss: 0.0000, Overall Loss: 0.0042\n",
      "\tBatch: [43/240], Batch Loss: 0.0000, Overall Loss: 0.0041\n",
      "\tBatch: [44/240], Batch Loss: 0.0000, Overall Loss: 0.0040\n",
      "\tBatch: [45/240], Batch Loss: 0.0000, Overall Loss: 0.0039\n",
      "\tBatch: [46/240], Batch Loss: 0.0000, Overall Loss: 0.0038\n",
      "\tBatch: [47/240], Batch Loss: 0.0000, Overall Loss: 0.0038\n",
      "\tBatch: [48/240], Batch Loss: 0.0465, Overall Loss: 0.0047\n",
      "\tBatch: [49/240], Batch Loss: 0.0000, Overall Loss: 0.0046\n",
      "\tBatch: [50/240], Batch Loss: 0.0000, Overall Loss: 0.0045\n",
      "\tBatch: [51/240], Batch Loss: 0.0000, Overall Loss: 0.0044\n",
      "\tBatch: [52/240], Batch Loss: 0.0000, Overall Loss: 0.0043\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Sakal\\AI_FARM\\Recycling_Classification\\src\\models\\detector_model\\loss.py:171\u001b[0m, in \u001b[0;36mObjectDetectionLoss.forward\u001b[1;34m(self, outputs, targets)\u001b[0m\n\u001b[0;32m    168\u001b[0m output \u001b[38;5;241m=\u001b[39m outputs[i]\n\u001b[0;32m    169\u001b[0m target \u001b[38;5;241m=\u001b[39m targets[i]\n\u001b[1;32m--> 171\u001b[0m pred_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_yolo_output_to_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m gt_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mconvert_yolo_output_to_bboxes(target, class_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    174\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_single_image_loss(pred_data, gt_data, device)\n",
      "File \u001b[1;32md:\\Sakal\\AI_FARM\\Recycling_Classification\\src\\models\\detector_model\\processor.py:372\u001b[0m, in \u001b[0;36mTrainingProcessor.convert_yolo_output_to_bboxes\u001b[1;34m(self, output_tensor, class_tensor, conf_threshold, input_size, num_classes, num_anchors, grid_size, is_training)\u001b[0m\n\u001b[0;32m    369\u001b[0m conf \u001b[38;5;241m=\u001b[39m anchor_data[\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_training \u001b[38;5;129;01mand\u001b[39;00m conf\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m conf_threshold) \u001b[38;5;129;01mor\u001b[39;00m (is_training \u001b[38;5;129;01mand\u001b[39;00m conf \u001b[38;5;241m<\u001b[39m conf_threshold):\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    374\u001b[0m class_base \u001b[38;5;241m=\u001b[39m (num_anchors \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m+\u001b[39m anchor \u001b[38;5;241m*\u001b[39m num_classes\n\u001b[0;32m    375\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m output_tensor[i, j, class_base: class_base \u001b[38;5;241m+\u001b[39m num_classes]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  \n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(trash_dataloader):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate for epoch average\n",
    "        epoch_loss += loss.item()  # Add current batch loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        if i % batch_interval == 0:\n",
    "            print(f'\\tBatch: [{i+1}/{len(trash_dataloader)}], Batch Loss: {loss.item():.4f}, Overall Loss: {(epoch_loss / num_batches):.4f}')\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    print(f'Epoch: [{epoch+1}/{num_epochs}], Avg Loss: {avg_epoch_loss:.4f}')\n",
    "    epoch_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a7bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.binary_focal_loss.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865763e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4808c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detector_model.model import ObjectDetectionModel\n",
    "from models.detector_model.processor import TrainingProcessor\n",
    "from models.detector_model.data_utils import TrainingDataset, COCOProcessor\n",
    "from models.detector_model.loss1 import ObjectDetectionLoss, train_with_monitoring, create_balanced_loss\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "grouped_classes = {\n",
    "        \"Metal\": [\n",
    "            \"Metal bottle cap\", \"Metal lid\", \"Drink can\", \"Pop tab\", \"Scrap metal\",\n",
    "            \"Food Can\", \"Aluminium blister pack\", \"Aluminium foil\", \"Aerosol\"\n",
    "        ],\n",
    "        \"Plastic\": [\n",
    "            \"Plastic bottle cap\", \"Other plastic wrapper\", \"Six pack rings\",\n",
    "            \"Single-use carrier bag\", \"Plastic straw\", \"Plastic glooves\",\n",
    "            \"Plastic utensils\", \"Disposable plastic cup\", \"Other plastic bottle\",\n",
    "            \"Tupperware\", \"Spread tub\", \"Garbage bag\", \"Other plastic container\",\n",
    "            \"Other plastic\", \"Rope & strings\", \"Other plastic cup\", \"Plastic film\",\n",
    "            \"Polypropylene bag\", \"Plastic lid\", \"Clear plastic bottle\", \"Squeezable tube\",\n",
    "            \"Carded blister pack\", \"Crisp packet\", \"Meal carton\"\n",
    "        ],\n",
    "        \"Paper\": [\n",
    "            \"Paper cup\", \"Paper bag\", \"Normal paper\", \"Paper straw\", \"Tissues\",\n",
    "            \"Toilet tube\", \"Wrapping paper\", \"Pizza box\", \"Magazine paper\",\n",
    "            \"Corrugated carton\", \"Egg carton\", \"Other carton\", \"Drink carton\"\n",
    "        ],\n",
    "        \"Glass\": [\n",
    "            \"Glass jar\", \"Glass bottle\", \"Glass cup\", \"Broken glass\"\n",
    "        ],\n",
    "        \"Waste\": [\n",
    "            \"Cigarette\", \"Food waste\", \"Foam cup\",\n",
    "            \"Disposable food container\", \"Foam food container\",\n",
    "            \"Shoe\", \"Unlabeled litter\", \"Styrofoam piece\"\n",
    "        ],\n",
    "        \"Battery\": [\n",
    "            \"Battery\"\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0db955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL PARAMETER SUMMARY\n",
      "==================================================\n",
      "Total parameters:      390,700\n",
      "Trainable parameters:  390,700\n",
      "Non-trainable params:  0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "model = ObjectDetectionModel(num_classes=len(grouped_classes), num_anchors=4, grid_size=4)\n",
    "model.count_parameters()\n",
    "coco_processor = COCOProcessor(classes=grouped_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d701f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_trash = coco_processor.extract_annotations(\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/Dataset/Trash Detection.v14i.coco/train/_annotations.coco.json',\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/Dataset/Trash Detection.v14i.coco/train',\n",
    "    convert=False\n",
    ")\n",
    "\n",
    "extracted_taco = coco_processor.extract_annotations(\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/TACO/data/annotations.json',\n",
    "    'D:/Sakal/AI_FARM/Recycling_Classification/Dataset/TACO/data',\n",
    "    convert=True\n",
    ")\n",
    "\n",
    "classes_names_trash = []\n",
    "for label in extracted_trash:\n",
    "    classes_names_trash.extend(label['Class'])\n",
    "classes_names_trash = list(set(classes_names_trash))\n",
    "\n",
    "classes_names_taco = []\n",
    "for label in extracted_taco:\n",
    "    classes_names_taco.extend(label['Class'])\n",
    "classes_names_taco = list(set(classes_names_taco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef08bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "classes = [item for item, value in grouped_classes.items()] # ['Metal', 'Plastic', 'Paper', 'Glass', 'Waste', 'Battery']\n",
    "\n",
    "processor = TrainingProcessor(\n",
    "    input_size=448,\n",
    "    grid_size=model.grid_size,\n",
    "    num_anchors=model.num_anchors,\n",
    "    classes=classes,\n",
    ")\n",
    "\n",
    "trash_dataset = TrainingDataset(data_json=extracted_trash, processor=processor, is_training=False)\n",
    "trash_dataloader = DataLoader(trash_dataset, batch_size=40, shuffle=True)\n",
    "\n",
    "# image_tensor, target_tensor, anchor_pose = processor.process_training_sample(\n",
    "#     extracted_trash[90], apply_augmentation=False, get_anchors=True)\n",
    "\n",
    "# # processor.visualize_training_sample(\n",
    "# #     image_tensor, target_tensor, anchor_pose,)\n",
    "\n",
    "# bboxes = processor.convert_yolo_output_to_bboxes(target_tensor, grid=True, class_tensor=True, is_training=True)\n",
    "# processor.draw_bbox_on_image(image_tensor, bboxes, tensor=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ceb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# criterion = ObjectDetectionLoss(processor=processor, classes_alpha=[0.3,0.4,0.3,0.1,0.3,0.2])\n",
    "# criterion = ObjectDetectionLoss(processor=processor, classes_alpha=[0.3,0.4,0.3,0.1,0.3,0.2])\n",
    "criterion = create_balanced_loss(processor)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,           # learning rate\n",
    "    betas=(0.9, 0.999),# beta1 and beta2 for momentum estimates\n",
    "    eps=1e-8,          # small constant for numerical stability\n",
    "    weight_decay=0     # L2 regularization\n",
    ")\n",
    "\n",
    "num_epochs = 50\n",
    "batch_interval = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cb5a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training log loaded from detection_training.json\n",
      "Starting training with enhanced monitoring...\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 0, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 11.3347 (overall: 13.7867) ‚û°Ô∏è\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 1.6320 (overall: 4.0532) ‚û°Ô∏è\n",
      "   cls_loss    : 0.5634 (overall: 0.7058) ‚û°Ô∏è\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     1.166505 (changing)\n",
      "   Trend:        -0.140719 (improving)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚úÖ Training progressing well!\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.021, Obj: 0.491, Cls: 2.391\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.040, Obj: 0.663, Cls: 3.197\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.059, Obj: 0.819, Cls: 3.876\n",
      "üìä Training phase: increasing\n",
      "\n",
      "üéØ Epoch 1/50 completed:\n",
      "   Average Loss: 14.9334\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 1, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 16.0560 (overall: 14.3843) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.4728) ‚û°Ô∏è\n",
      "   cls_loss    : 1.0518 (overall: 0.8542) ‚û°Ô∏è\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.742407 (changing)\n",
      "   Trend:        0.186264 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.71s\n",
      "\n",
      "üìä CURRENT PHASE: INCREASING\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   1. Loss increasing rapidly - consider reducing learning rate\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.073, Obj: 0.958, Cls: 4.567\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.086, Obj: 1.082, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.096, Obj: 1.193, Cls: 5.000\n",
      "üìä Training phase: decreasing\n",
      "\n",
      "üéØ Epoch 2/50 completed:\n",
      "   Average Loss: 19.7086\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 2, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 20.3069 (overall: 16.1597) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.6481) ‚û°Ô∏è\n",
      "   cls_loss    : 0.9979 (overall: 0.9088) üìà\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.589052 (changing)\n",
      "   Trend:        0.192792 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.71s\n",
      "\n",
      "üìä CURRENT PHASE: DECREASING\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚úÖ Training progressing well!\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.107, Obj: 1.294, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.116, Obj: 1.385, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.126, Obj: 1.468, Cls: 5.000\n",
      "üìä Training phase: stable\n",
      "\n",
      "üéØ Epoch 3/50 completed:\n",
      "   Average Loss: 21.9907\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 3, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 22.4001 (overall: 17.6194) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.7359) ‚û°Ô∏è\n",
      "   cls_loss    : 1.0252 (overall: 0.9317) üìà\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.850007 (changing)\n",
      "   Trend:        0.153163 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.72s\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  Monitor for signs of convergence\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.137, Obj: 1.545, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.147, Obj: 1.614, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.154, Obj: 1.674, Cls: 5.000\n",
      "üìä Training phase: decreasing\n",
      "\n",
      "üéØ Epoch 4/50 completed:\n",
      "   Average Loss: 24.1266\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 4, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 24.3402 (overall: 18.9213) ‚û°Ô∏è\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.7887) ‚û°Ô∏è\n",
      "   cls_loss    : 1.1439 (overall: 0.9744) ‚û°Ô∏è\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.656243 (changing)\n",
      "   Trend:        -0.001243 (improving)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.73s\n",
      "\n",
      "üìä CURRENT PHASE: DECREASING\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  Monitor for signs of convergence\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.161, Obj: 1.729, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.167, Obj: 1.779, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.172, Obj: 1.822, Cls: 5.000\n",
      "üìä Training phase: stable\n",
      "\n",
      "üéØ Epoch 5/50 completed:\n",
      "   Average Loss: 25.1637\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 5, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 25.3264 (overall: 19.9613) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.8239) ‚û°Ô∏è\n",
      "   cls_loss    : 1.1455 (overall: 1.0026) üìà\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.490470 (changing)\n",
      "   Trend:        0.130935 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.74s\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  Monitor for signs of convergence\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.179, Obj: 1.863, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.181, Obj: 1.897, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.184, Obj: 1.929, Cls: 5.000\n",
      "\n",
      "üéØ Epoch 6/50 completed:\n",
      "   Average Loss: 25.6147\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 6, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 25.6035 (overall: 20.7689) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.8490) ‚û°Ô∏è\n",
      "   cls_loss    : 1.0593 (overall: 1.0142) üìà\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.331765 (changing)\n",
      "   Trend:        0.137221 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.72s\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  Monitor for signs of convergence\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.188, Obj: 1.958, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.190, Obj: 1.984, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.193, Obj: 2.006, Cls: 5.000\n",
      "\n",
      "üéØ Epoch 7/50 completed:\n",
      "   Average Loss: 26.2161\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 7, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 26.2286 (overall: 21.4483) ‚û°Ô∏è\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.8679) ‚û°Ô∏è\n",
      "   cls_loss    : 1.0846 (overall: 1.0245) ‚û°Ô∏è\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.236376 (changing)\n",
      "   Trend:        -0.002061 (improving)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.73s\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚úÖ Training progressing well!\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.196, Obj: 2.028, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.196, Obj: 2.046, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.198, Obj: 2.062, Cls: 5.000\n",
      "\n",
      "üéØ Epoch 8/50 completed:\n",
      "   Average Loss: 26.2555\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 8, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 26.2670 (overall: 21.9824) üìâ\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.8825) ‚û°Ô∏è\n",
      "   cls_loss    : 1.0197 (overall: 1.0250) üìâ\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.177833 (changing)\n",
      "   Trend:        -0.066534 (improving)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.70s\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  Monitor for signs of convergence\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.196, Obj: 2.074, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.087, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.198, Obj: 2.099, Cls: 5.000\n",
      "üìä Training phase: increasing\n",
      "\n",
      "üéØ Epoch 9/50 completed:\n",
      "   Average Loss: 26.3379\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 9, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 26.4132 (overall: 22.4172) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.8943) ‚û°Ô∏è\n",
      "   cls_loss    : 1.0050 (overall: 1.0220) üìà\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.692034 (changing)\n",
      "   Trend:        0.145545 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.70s\n",
      "\n",
      "üìä CURRENT PHASE: INCREASING\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   1. Loss increasing rapidly - consider reducing learning rate\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.108, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.116, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.199, Obj: 2.127, Cls: 5.000\n",
      "üìä Training phase: plateau\n",
      "\n",
      "üéØ Epoch 10/50 completed:\n",
      "   Average Loss: 26.4452\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 10, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 26.5299 (overall: 22.7833) üìâ\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.9039) ‚û°Ô∏è\n",
      "   cls_loss    : 0.9964 (overall: 1.0185) üìâ\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.230285 (changing)\n",
      "   Trend:        -0.093728 (improving)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.70s\n",
      "\n",
      "üìä CURRENT PHASE: PLATEAU\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚úÖ Training progressing well!\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.198, Obj: 2.133, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.139, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.144, Cls: 5.000\n",
      "üìä Training phase: stable\n",
      "\n",
      "üéØ Epoch 11/50 completed:\n",
      "   Average Loss: 26.5459\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 11, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 26.4639 (overall: 23.0965) üìà\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.9119) ‚û°Ô∏è\n",
      "   cls_loss    : 0.9591 (overall: 1.0151) ‚û°Ô∏è\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.289054 (changing)\n",
      "   Trend:        0.023372 (worsening)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    0.74s\n",
      "\n",
      "üìä CURRENT PHASE: STABLE\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚úÖ Training progressing well!\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.198, Obj: 2.150, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.155, Cls: 5.000\n",
      "üîÑ Adaptive weights updated:\n",
      "   Box: 2.197, Obj: 2.159, Cls: 5.000\n",
      "üìä Training phase: increasing\n",
      "\n",
      "üéØ Epoch 12/50 completed:\n",
      "   Average Loss: 26.6513\n",
      "   Best Loss: 11.0620 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "TRAINING STATUS - Epoch 12, Batch 0\n",
      "============================================================\n",
      "üìà CURRENT METRICS:\n",
      "   total_loss  : 26.6823 (overall: 23.3706) üìâ\n",
      "   box_loss    : 5.0000 (overall: 5.0000) ‚û°Ô∏è\n",
      "   obj_loss    : 5.0000 (overall: 4.9187) ‚û°Ô∏è\n",
      "   cls_loss    : 0.9865 (overall: 1.0128) ‚û°Ô∏è\n",
      "\n",
      "üîç LEARNING DYNAMICS:\n",
      "   Variance:     0.149374 (changing)\n",
      "   Trend:        -0.025637 (improving)\n",
      "   Best loss:    11.0620 (epoch 0)\n",
      "\n",
      "‚è±Ô∏è  TIMING:\n",
      "   Avg batch:    1.34s\n",
      "\n",
      "üìä CURRENT PHASE: INCREASING\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  Monitor for signs of convergence\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m monitor \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_monitoring\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrash_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# scheduler=scheduler,\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print status every 25 batches\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Sakal\\AI_FARM\\Recycling_Classification\\src\\models\\detector_model\\loss1.py:1154\u001b[0m, in \u001b[0;36mtrain_with_monitoring\u001b[1;34m(model, dataloader, loss_fn, optimizer, num_epochs, scheduler, save_model_path, monitor_frequency, device)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m-> 1154\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1155\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m loss_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss_dict)\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Miniconda\\envs\\General_LLM\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Sakal\\AI_FARM\\Recycling_Classification\\src\\models\\detector_model\\loss1.py:1279\u001b[0m, in \u001b[0;36mAdaptiveObjectDetectionLoss.forward\u001b[1;34m(self, outputs, targets)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     pred_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mconvert_yolo_output_to_bboxes(\n\u001b[0;32m   1277\u001b[0m         outputs[i], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, class_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m     )\n\u001b[1;32m-> 1279\u001b[0m     gt_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_yolo_output_to_bboxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m     loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_single_image_loss(pred_data, gt_data, device)\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_valid_loss(loss_dict):\n",
      "File \u001b[1;32md:\\Sakal\\AI_FARM\\Recycling_Classification\\src\\models\\detector_model\\processor.py:372\u001b[0m, in \u001b[0;36mTrainingProcessor.convert_yolo_output_to_bboxes\u001b[1;34m(self, output_tensor, class_tensor, grid, conf_threshold, input_size, num_classes, num_anchors, grid_size, is_training)\u001b[0m\n\u001b[0;32m    369\u001b[0m conf \u001b[38;5;241m=\u001b[39m anchor_data[\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_training \u001b[38;5;129;01mand\u001b[39;00m conf\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m conf_threshold) \u001b[38;5;129;01mor\u001b[39;00m (is_training \u001b[38;5;129;01mand\u001b[39;00m conf \u001b[38;5;241m<\u001b[39m conf_threshold):\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    374\u001b[0m class_base \u001b[38;5;241m=\u001b[39m (num_anchors \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m+\u001b[39m anchor \u001b[38;5;241m*\u001b[39m num_classes\n\u001b[0;32m    375\u001b[0m class_probs \u001b[38;5;241m=\u001b[39m output_tensor[i, j, class_base: class_base \u001b[38;5;241m+\u001b[39m num_classes]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "monitor = train_with_monitoring(\n",
    "    model=model,\n",
    "    dataloader=trash_dataloader,\n",
    "    loss_fn=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=50,\n",
    "    # scheduler=scheduler,\n",
    "    save_model_path='best_model.pth',\n",
    "    monitor_frequency=200, \n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc997375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid-based matching failed: 'FixedObjectDetectionLoss' object has no attribute '_compute_grid_based_loss', falling back to direct matching\n",
      "\tBatch: [75/150], Interval Loss: 1.5043, Epoch Loss: 1.4845, Lifetime Loss: 1.4845\n",
      "Epoch: [1/50], Avg Epoch Loss: 1.5115, Avg Lifetime Loss: 1.5115\n",
      "\tBatch: [75/150], Interval Loss: 1.8156, Epoch Loss: 1.7917, Lifetime Loss: 1.6057\n",
      "Epoch: [2/50], Avg Epoch Loss: 1.9637, Avg Lifetime Loss: 1.7376\n",
      "\tBatch: [75/150], Interval Loss: 2.2849, Epoch Loss: 2.2548, Lifetime Loss: 1.8421\n",
      "Epoch: [3/50], Avg Epoch Loss: 2.2099, Avg Lifetime Loss: 1.8950\n",
      "\tBatch: [75/150], Interval Loss: 2.2155, Epoch Loss: 2.1863, Lifetime Loss: 1.9371\n",
      "Epoch: [4/50], Avg Epoch Loss: 2.1500, Avg Lifetime Loss: 1.9588\n",
      "\tBatch: [75/150], Interval Loss: 2.0564, Epoch Loss: 2.0294, Lifetime Loss: 1.9667\n",
      "Epoch: [5/50], Avg Epoch Loss: 2.0719, Avg Lifetime Loss: 1.9814\n",
      "\tBatch: [75/150], Interval Loss: 2.2168, Epoch Loss: 2.1876, Lifetime Loss: 2.0004\n",
      "Epoch: [6/50], Avg Epoch Loss: 2.1570, Avg Lifetime Loss: 2.0106\n",
      "\tBatch: [75/150], Interval Loss: 2.1587, Epoch Loss: 2.1303, Lifetime Loss: 2.0200\n",
      "Epoch: [7/50], Avg Epoch Loss: 2.1186, Avg Lifetime Loss: 2.0261\n",
      "\tBatch: [75/150], Interval Loss: 2.1333, Epoch Loss: 2.1052, Lifetime Loss: 2.0314\n",
      "Epoch: [8/50], Avg Epoch Loss: 2.0857, Avg Lifetime Loss: 2.0335\n",
      "\tBatch: [75/150], Interval Loss: 2.0808, Epoch Loss: 2.0534, Lifetime Loss: 2.0347\n",
      "Epoch: [9/50], Avg Epoch Loss: 2.0758, Avg Lifetime Loss: 2.0382\n",
      "\tBatch: [75/150], Interval Loss: 2.0923, Epoch Loss: 2.0648, Lifetime Loss: 2.0396\n",
      "Epoch: [10/50], Avg Epoch Loss: 2.0670, Avg Lifetime Loss: 2.0411\n",
      "\tBatch: [75/150], Interval Loss: 2.0752, Epoch Loss: 2.0479, Lifetime Loss: 2.0414\n",
      "Epoch: [11/50], Avg Epoch Loss: 2.0622, Avg Lifetime Loss: 2.0430\n",
      "\tBatch: [75/150], Interval Loss: 2.0531, Epoch Loss: 2.0261, Lifetime Loss: 2.0423\n",
      "Epoch: [12/50], Avg Epoch Loss: 2.0219, Avg Lifetime Loss: 2.0412\n",
      "\tBatch: [75/150], Interval Loss: 2.0008, Epoch Loss: 1.9744, Lifetime Loss: 2.0385\n",
      "Epoch: [13/50], Avg Epoch Loss: 1.9936, Avg Lifetime Loss: 2.0376\n",
      "\tBatch: [75/150], Interval Loss: 2.0044, Epoch Loss: 1.9781, Lifetime Loss: 2.0354\n",
      "Epoch: [14/50], Avg Epoch Loss: 1.9726, Avg Lifetime Loss: 2.0329\n",
      "\tBatch: [75/150], Interval Loss: 2.0669, Epoch Loss: 2.0397, Lifetime Loss: 2.0332\n",
      "Epoch: [15/50], Avg Epoch Loss: 2.0113, Avg Lifetime Loss: 2.0315\n",
      "\tBatch: [75/150], Interval Loss: 2.0423, Epoch Loss: 2.0154, Lifetime Loss: 2.0310\n",
      "Epoch: [16/50], Avg Epoch Loss: 1.9999, Avg Lifetime Loss: 2.0295\n",
      "\tBatch: [75/150], Interval Loss: 2.0190, Epoch Loss: 1.9924, Lifetime Loss: 2.0284\n",
      "Epoch: [17/50], Avg Epoch Loss: 1.9994, Avg Lifetime Loss: 2.0278\n",
      "\tBatch: [75/150], Interval Loss: 2.0003, Epoch Loss: 1.9740, Lifetime Loss: 2.0262\n",
      "Epoch: [18/50], Avg Epoch Loss: 1.9440, Avg Lifetime Loss: 2.0231\n",
      "\tBatch: [75/150], Interval Loss: 1.9966, Epoch Loss: 1.9703, Lifetime Loss: 2.0217\n",
      "Epoch: [19/50], Avg Epoch Loss: 1.9755, Avg Lifetime Loss: 2.0206\n"
     ]
    }
   ],
   "source": [
    "# model.to(device)\n",
    "# training_lifetime_loss = 0.0\n",
    "# training_lifetime_batch = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()  # Ensure model is in training mode\n",
    "#     epoch_loss = 0.0\n",
    "#     batch_interval_loss = 0.0\n",
    "#     num_batches = 0\n",
    "    \n",
    "#     for i, (x, y) in enumerate(trash_dataloader):\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         y_pred = model(x)\n",
    "#         loss = criterion(y_pred, y)['total_loss']\n",
    "        \n",
    "#         # Check for invalid loss values\n",
    "#         if torch.isnan(loss) or torch.isinf(loss):\n",
    "#             print(f\"Warning: Invalid loss detected at epoch {epoch+1}, batch {i}\")\n",
    "#             print(f\"Loss value: {loss.item()}\")\n",
    "#             continue  # Skip this batch\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Add gradient clipping for stability (especially important for your loss function)\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        \n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Accumulate losses\n",
    "#         loss_item = loss.item()\n",
    "#         epoch_loss += loss_item\n",
    "#         batch_interval_loss += loss_item\n",
    "#         training_lifetime_loss += loss_item\n",
    "#         num_batches += 1\n",
    "#         training_lifetime_batch += 1\n",
    "        \n",
    "#         # Print batch interval statistics\n",
    "#         if i % batch_interval == 0 and i != 0:\n",
    "#             avg_interval_loss = batch_interval_loss / batch_interval  # Fixed division\n",
    "#             avg_epoch_loss_so_far = epoch_loss / num_batches\n",
    "#             avg_lifetime_loss = training_lifetime_loss / training_lifetime_batch\n",
    "            \n",
    "#             print(f'\\tBatch: [{i}/{len(trash_dataloader)}], '\n",
    "#                   f'Interval Loss: {avg_interval_loss:.4f}, '\n",
    "#                   f'Epoch Loss: {avg_epoch_loss_so_far:.4f}, '\n",
    "#                   f'Lifetime Loss: {avg_lifetime_loss:.4f}')\n",
    "            \n",
    "#             batch_interval_loss = 0.0\n",
    "    \n",
    "#     # Epoch summary\n",
    "#     if num_batches > 0:  # Avoid division by zero\n",
    "#         avg_epoch_loss = epoch_loss / num_batches\n",
    "#         avg_lifetime_loss = training_lifetime_loss / training_lifetime_batch\n",
    "        \n",
    "#         print(f'Epoch: [{epoch+1}/{num_epochs}], '\n",
    "#               f'Avg Epoch Loss: {avg_epoch_loss:.4f}, '\n",
    "#               f'Avg Lifetime Loss: {avg_lifetime_loss:.4f}')\n",
    "        \n",
    "#         # Optional: Save checkpoint periodically\n",
    "#         if (epoch + 1) % 25 == 0:  # Save every 5 epochs\n",
    "#             checkpoint = {\n",
    "#                 'epoch': epoch + 1,\n",
    "#                 'model_state_dict': model.state_dict(),\n",
    "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                 'loss': avg_epoch_loss,\n",
    "#                 'lifetime_loss': avg_lifetime_loss\n",
    "#             }\n",
    "#             torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "#             print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "# print(\"Training completed!\")\n",
    "# print(f\"Final average lifetime loss: {training_lifetime_loss / training_lifetime_batch:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24603323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.1836], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss['total_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a7bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.binary_focal_loss.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865763e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
